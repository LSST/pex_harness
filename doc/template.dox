/**

\page Example_Template Template for testing an application Stage in a Pipeline

The template example demonstrates how to set up a simple Pipeline with a single Slice 
executing a single Stage.  This example is found under pex_harness/examples/template/ .

The template example has a single application stage, SampleStage (which may be 
found in  pex_harness/examples/stages/lsst/pexhexamples/pipeline.py). 


The SampleStage is a dummy application stage that performs a few simple tasks: 
-# overwrites the preprocess(), process(), postprocess() methods of generic Stage, 
-# retrieves the Clipboard from its inputQueue at the start of the process() method,
   and posts it to the outputQueue at the end, ushering the Clipboard on to the next Stage 
   that a Slice will process,
-# retrieves the Clipboard from its inputQueue at the start of the preprocess() method,
   and posts it to the outputQueue at the end of postprocess(), passing the Clipboard to the
   next Stage for serial processing in the main Pipeline,
-# creates an instance of the Log,
-# retrieves elements from its stage policy file and write them to the Log. 

As such, the SampleStage can serve as a useful template for building other application
Stage that perform actual computation.  The source for SampleStage : 
\code
from lsst.pex.harness.Stage import Stage
import lsst.pex.harness.Utils
from lsst.pex.logging import Log, LogRec
import lsst.daf.base as dafBase
from lsst.daf.base import *

class SampleStage(Stage):

    def preprocess(self):
        """
        Processing code for this Stage to be executed by the main Pipeline 
        prior to invoking Slice process 
        """
        self.activeClipboard = self.inputQueue.getNextDataset()

        root =  Log.getDefaultLog()
        log = Log(root, "lsst.pexhexamples.pipeline.SampleStage.preprocess")

        log.log(Log.INFO, 'SampleStage preprocess')

    def postprocess(self):
        """
        Processing code for this Stage to be executed by the main Pipeline 
        after the completion of Slice process 
        """
        root =  Log.getDefaultLog()

        log = Log(root, "lsst.pexhexamples.pipeline.SampleStage.postprocess")
        log.log(Log.INFO, 'SampleStage postprocess')

        self.outputQueue.addDataset(self.activeClipboard)

    def process(self):

        self.activeClipboard = self.inputQueue.getNextDataset()

        root =  Log.getDefaultLog()
        log = Log(root, "lsst.pexhexamples.pipeline.SampleStage.process")

        value ="None"
        if self._policy.exists('RunMode'):
            value = self._policy.getString('RunMode')

        lr = LogRec(log, Log.INFO)
        lr << " rank " + str(self._rank)
        lr << " stageId " + str(self.stageId)
        lr << " universeSize " + str(self._universeSize)
        lr << " RunMode from Policy " + value
        lr << LogRec.endr

        self.outputQueue.addDataset(self.activeClipboard)

\endcode

By default this example will run with the Pipeline with one Slice on a single node.
Edit the MPI machinefile "nodelist.scr" to specify the hostname of the current host.

The full path to the directory pex_harness/examples/stages should be added to the PYTHONPATH:
\code 
% export PYTHONPATH ${PWD}/../stages:${PYTHONPATH}    (bash)
% setenv PYTHONPATH ${PWD}/../stages:${PYTHONPATH}    (tcsh)
\endcode

The pipeline is then executed via 
\code
% launchPipeline.py template_policy.paf <some-run-id>
\endcode

such as  

\code
% launchPipeline.py template_policy.paf test_1090
\endcode

After execution the messages from the SampleStage process()

\code
lsst.pexhexamples.pipeline.SampleStage.process:  rank 0
lsst.pexhexamples.pipeline.SampleStage.process:  stageId 1
lsst.pexhexamples.pipeline.SampleStage.process:  universeSize 2
lsst.pexhexamples.pipeline.SampleStage.process:  RunMode from Policy process
\endcode

are located within Slice0.log, and the messages 

\code 
...
lsst.pexhexamples.pipeline.SampleStage.preprocess: SampleStage preprocess
...
lsst.pexhexamples.pipeline.SampleStage.postprocess: SampleStage postprocess
\endcode
are located within Pipeline.log.

Although this example does not use events, 
the events system does make use of an ActiveMQ broker during initialization. If an ActiveMQ broker ("eventHostBroker") 
other than the LSST default (lsst8.ncsa.uiuc.edu) is used, this needs to be specified 
in the pipeline policy file under "eventBrokerHost". 

*/

//-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-

